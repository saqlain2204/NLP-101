



# NLP-101

Welcome to **NLP-101**, a comprehensive course and resource hub for Natural Language Processing. This repository contains code, notes, and experiments to help you learn and apply NLP concepts and techniques.

**Repository URL:** [https://github.com/saqlain2204/NLP-101](https://github.com/saqlain2204/NLP-101)

## Course Structure

### Language Modeling
This module covers:
- Fundamental concepts of language modeling
- Tokenization techniques (including BPE)
- Resource accounting for efficient model training




## Language Modeling Contents

| Topic                | Description                                                                | Resources                                                                 |
|----------------------|----------------------------------------------------------------------------|---------------------------------------------------------------------------|
| Byte Pair Encoding   | Subword tokenization algorithm for representing common character sequences | [BPE Guide](docs/Language-Modeling/Tokenization/BPE/README.md) (implementation included in the README) |
| Resource Accounting  | Understanding tensor memory, precision types, and training efficiency      | [Resource Accounting Guide](docs/Language-Modeling/Resource%20Accounting/README.md) |
| Architectures & Hyperparameters | Guidance on model architecture choices, normalization, activations, and hyperparameter trade-offs | [Architectures & Hyperparameters](docs/Language-Modeling/Architectures%20and%20Hyperparameters/README.md) |

## References

- [CS336 Lecture Videos](https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3q8h6KP2RrT)

